import gradio as gr
from typing import List
import webbrowser
from app.knowledgebase import KnowledgeBase
from app.chatllm import ChatMemoryLLM


class RAGChatApp:
    def __init__(self):
        self.kb = KnowledgeBase()
        self.llm = ChatMemoryLLM()
        self.is_kb_ready = False

    def load_pdfs(self, file_paths: List[str]):
        """åŠ è½½ PDF å¹¶æ„å»º FAISS çŸ¥è¯†åº“"""
        if not file_paths:
            return "âŒ è¯·å…ˆä¸Šä¼  PDF æ–‡ä»¶ï¼"

        result = self.kb.process_pdfs(file_paths)

        if result.get("indexed", 0) > 0:
            self.is_kb_ready = True

        summary_lines = []
        for item in result["summary"]:
            if item["status"] == "ok":
                summary_lines.append(f"âœ… {item['file']} å¤„ç†æˆåŠŸï¼Œå…± {item['chunks']} ä¸ªæ–‡æœ¬å—")
            else:
                summary_lines.append(f"âŒ {item['file']} å¤„ç†å¤±è´¥: {item['error']}")
        summary_lines.append(
            f"\nğŸ“Š æœ¬æ¬¡æ–°å¢ {result['indexed']} ä¸ªæ–‡æœ¬å—ï¼Œå½“å‰æ€»ç´¢å¼• {result['total_indexed']} ä¸ª"
        )

        return "\n".join(summary_lines)

    def chat(self, query: str, history: list, top_k: int = 3):
        """RAG èŠå¤©ï¼šæ£€ç´¢ + è®°å¿†å¯¹è¯"""
        if not self.is_kb_ready or self.kb.faiss_index is None:
            return history + [["ç”¨æˆ·", query], ["ç³»ç»Ÿ", "âš ï¸ çŸ¥è¯†åº“æœªå°±ç»ªï¼Œè¯·å…ˆä¸Šä¼  PDF"]]

        # 1. å‘é‡æ£€ç´¢
        query_emb = self.kb.embed_model.encode([query], convert_to_numpy=True).astype("float32")
        distances, indices = self.kb.faiss_index.search(query_emb, top_k)

        retrieved_chunks = []
        for idx in indices[0]:
            if idx == -1:
                continue
            chunk_id = self.kb.faiss_id_order_for_index[idx]
            retrieved_chunks.append(self.kb.faiss_contents_map[chunk_id])

        if not retrieved_chunks:
            return history + [[query, "âš ï¸ æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹"]]

        # 2. æ„é€ ä¸Šä¸‹æ–‡
        context = "\n\n".join(retrieved_chunks)
        prompt = f"åŸºäºä»¥ä¸‹å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š\n\n{context}\n\nç”¨æˆ·é—®é¢˜ï¼š{query}"

        # 3. è°ƒç”¨å¸¦ memory çš„ LLM
        answer = self.llm.chat(prompt)

        # 4. æŠŠè¿™è½®å¯¹è¯åŠ å…¥ historyï¼ˆGradio Chatbot ç”¨ [user, bot]ï¼‰
        history.append([query, answer])
        return history

    def reset_chat(self):
        """æ¸…ç©ºå†å² + LLM memory"""
        self.llm.reset()
        return []


def create_interface(app: RAGChatApp):
    with gr.Blocks() as demo:
        gr.Markdown("## ğŸ“„ PDF RAG èŠå¤©åŠ©æ‰‹")

        with gr.Tabs():
            # ---------------- Tab 1: PDF ä¸Šä¼  ----------------
            with gr.TabItem("ğŸ“„ ä¸Šä¼  PDF"):
                with gr.Row():
                    file_input = gr.File(
                        label="ä¸Šä¼  PDF",
                        type="filepath",
                        file_types=[".pdf"],
                        file_count="multiple",
                    )
                    load_btn = gr.Button("ğŸ“¥ å¯¼å…¥å¹¶æ„å»ºçŸ¥è¯†åº“")

                load_output = gr.Textbox(label="åŠ è½½ç»“æœ", lines=6)

                # ç»‘å®šäº‹ä»¶
                load_btn.click(fn=app.load_pdfs, inputs=file_input, outputs=load_output)

            # ---------------- Tab 2: èŠå¤© ----------------
            with gr.TabItem("ğŸ’¬ èŠå¤©"):
                chatbot = gr.Chatbot(label="å¯¹è¯çª—å£", height=500)
                query_input = gr.Textbox(label="è¯·è¾“å…¥é—®é¢˜", placeholder="åœ¨è¿™é‡Œæé—®...")
                with gr.Row():
                    send_btn = gr.Button("ğŸš€ å‘é€")
                    reset_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯")

                # ç»‘å®šäº‹ä»¶
                send_btn.click(fn=app.chat, inputs=[query_input, chatbot], outputs=chatbot)
                reset_btn.click(fn=app.reset_chat, outputs=chatbot)

    return demo


if __name__ == "__main__":
    app = RAGChatApp()
    demo = create_interface(app)
    webbrowser.open("http://127.0.0.1:7860")
    demo.launch(server_port=7860, server_name="0.0.0.0", show_error=True)
